# 应用python爬取数据
___
### 爬取目的

 `互联网信息海量，在较短时间内只需要某些特定的信息，此时运用定向爬虫技术，对内容进行筛选，爬取有效信息`

### 定向爬取步骤

##### 1. 理清爬取目的，明确要爬取的内容

##### 2. 设置爬取网址的过滤规则，如利用正则表达式等，然后爬取网页；这里需要注意，如果抓取被封的IP，会返回403，503错误码，所以在请求页面时，对速度加以控制，或更换不同cookie访问

##### 3. 设置内容采集规则，提取相关信息，过滤无关信息，同样可运用正则表达式辅助

##### 4. 规划好采集任务，合理的设置爬虫线程与爬虫数量，例如单线程爬虫和多线程爬虫

##### 5. 将采集结果进行相应的修正，处理成我们想要的格式

##### 6. 处理爬取结果，转换到想要的格式，如txt,html,json等

### 常用爬虫工具

* urllib与requests模块
  `get, post请求`
* [scrapy](https://github.com/vicjiafeng/python_application/blob/master/library/scrapy%E6%A1%86%E6%9E%B6.md)框架
 
* 分析工具-[beautfulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)/[HTMLParser](https://blog.csdn.net/weixin_35955795/article/details/52823203)/[lmxl]()
 
  `1. beautfulsoup4是一个用于从HTML和XML文档中提取数据的Python库，可以实现文档的导航、查找、修改.它把HTML这种基于标签的文档组织成树的结构，方便我们用面向对象的方式获取内容`
  
  `2. HTMLParser是python自带模块，实现html文件分析，使用时需要定义一个从模块html.parser中的类HTMLParser继承的类`
  
   >handle_starttag( tag, attrs)

  >handle_startendtag( tag, attrs)

  >handle_endtag( tag)

  >handle_data(data)
  
  `3. lxml 是python三方的结构匹配模块, lxml是python的一个解析库，支持HTML和XML的解析，支持XPath解析方式，而且解析效率非常高`
  
  >将爬虫获取到的HTML字符串转换为HTML结构图
  
  >xpath匹配获取数据
  
    *xpath语法*
  
  |表达式          |作用                |
  |---------------|-------------------|
  |/              |根结点选取           |
  |//             |在当前选择的文档中选取 |
  |.              |选取当前节点         |
  |..             |选取当前节点的父节点  |
  |@              |选取属性            | 
  
* 抓包工具-[fiddler](https://blog.csdn.net/a877415861/article/details/79447440)
 
  `键盘操作f12直接使用浏览器自带，也可以用fiddler抓包工具，利用Fiddler详细的对HTTP请求进行分析，并模拟对应的HTTP请求，使用工具可以分析复杂，甚至看不到的网址内容`
  
* 数据存储-pymongo库

    *步骤*

     1.导入PyMongo，实现python对MongoDB操作
   
     2.连接MongoDB时，我们需要使用PyMongo库里面的MongoClient
   
     3.指定数据库，如db=client.xx
   
     4.指定集合collection
   
     5.[增](https://www.runoob.com/python3/python-mongodb-insert-document.html)、[删](https://www.runoob.com/python3/python-mongodb-delete-document.html)、[改](https://www.runoob.com/python3/python-mongodb-update-document.html)、[查](https://www.runoob.com/python3/python-mongodb-query-document.html)

 #### 可视化

 * [matplotlib](https://matplotlib.org/2.0.2/contents.html):一个最基础的Python可视化库，作图风格接近MATLAB，所以称为matplotlib。一般都是从matplotlib上手Python数据可视化，然后开始做纵向与横向拓展
 
 * [seeborn](https://seaborn.pydata.org/tutorial.html):是一个基于matplotlib的高级可视化效果库，针对的点主要是数据挖掘和机器学习中的变量特征选取，seaborn可以用短小的代码去绘制描述更多维度数据的可视化效果图
 
 * [Plotly](https://plot.ly/):实现了在线导入数据做可视化并保存内容在云端server的功能
 
 * [mapbox](https://www.mapbox.com/):可以处理地理数据信息的可视化工具
 
 
