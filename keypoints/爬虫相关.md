# 应用python爬取数据
___
### 爬取目的

 `互联网信息海量，在较短时间内只需要某些特定的信息，此时运用定向爬虫技术，对内容进行筛选，爬取有效信息`

### 定向爬取步骤

##### 1. 理清爬取目的，明确要爬取的内容

##### 2. 设置爬取网址的过滤规则，如利用正则表达式等，然后爬取网页；这里需要注意，如果抓取被封的IP，会返回403，503错误码，所以在请求页面时，对速度加以控制，或更换不同cookie访问

##### 3. 设置内容采集规则，提取相关信息，过滤无关信息，同样可运用正则表达式辅助

##### 4. 规划好采集任务，合理的设置爬虫线程与爬虫数量，例如单线程爬虫和多线程爬虫

##### 5. 将采集结果进行相应的修正，处理成我们想要的格式

##### 6. 处理爬取结果，转换到想要的格式，如txt,html,json等

### 常用爬虫工具

* requests模块
  `get, post请求`
* [scrapy](https://github.com/vicjiafeng/python_application/blob/master/library/scrapy%E6%A1%86%E6%9E%B6.md)框架
 
* 分析工具-[beautfulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)/[HTMLParser](https://blog.csdn.net/weixin_35955795/article/details/52823203)/[lmxl]()
 
  `beautfulsoup4是一个用于从HTML和XML文档中提取数据的Python库，可以实现文档的导航、查找、修改.它把HTML这种基于标签的文档组织成树的结构，方便我们用面向对象的方式获取内容`
  `HTMLParser是python自带模块，实现html文件分析，使用时需要定义一个从模块html.parser中的类HTMLParser继承的类`
  >handle_starttag( tag, attrs)

  >handle_startendtag( tag, attrs)

  >handle_endtag( tag)

  >handle_data(data)
 
* 抓包工具-[fiddler](https://blog.csdn.net/a877415861/article/details/79447440)
 
  `键盘操作f12直接使用浏览器自带，也可以用fiddler抓包工具，利用Fiddler详细的对HTTP请求进行分析，并模拟对应的HTTP请求，使用工具可以分析复杂，甚至看不到的网址内容`


